'''
1. graph classfication
2. batch <----Loader
'''


#%%
import torch
from torch_geometric.datasets import TUDataset

dataset=TUDataset(root='data/TUDataset', name='MUTAG')
# %%
torch.manual_seed(12345)
dataset=dataset.shuffle()
train_dataset=dataset[:150]
test_dataset=dataset[150:]
print(f'Number of training graphs: {len(train_dataset)}')
print(f'Number of test graphs: {len(test_dataset)}')

# %%
# batch based on DataLoader
from torch_geometric.loader import DataLoader

train_loader= DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader= DataLoader(test_dataset, batch_size=64, shuffle=False)

#%%
'''
GNN for graph classfication
1. node embedding
2. graph embedding
3. classfication based on graph embedding
'''

from torch.nn import Linear
import torch.nn.functional as F
from torch_geometric.nn import GraphConv
from torch_geometric.nn import global_mean_pool

class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super(GCN, self).__init__()
        torch.manual_seed(12345)
        self.conv1=GraphConv(dataset.num_node_features, hidden_channels)
        self.conv2=GraphConv(hidden_channels,hidden_channels)
        self.conv3=GraphConv(hidden_channels,hidden_channels)
        self.lin=Linear(hidden_channels, dataset.num_classes)
    def forward(self, x, edge_index, batch):
        x=self.conv1(x, edge_index)
        x=x.relu()
        x=self.conv2(x, edge_index)
        x=x.relu()
        x=self.conv3(x, edge_index)

        x=global_mean_pool(x, batch)
        x=F.dropout(x, p=0.5, training=self.training)
        x=self.lin(x)

        return x
model=GCN(hidden_channels=64)
optimizer=torch.optim.Adam(model.parameters(),lr=0.01)
criterion=torch.nn.CrossEntropyLoss()

def train():
    model.train()
    for data in train_loader:
        out=model(data.x, data.edge_index,data.batch)
        loss=criterion(out, data.y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()
def test(loader):
    model.eval()

    correct=0
    for data in loader:
        out=model(data.x, data.edge_index, data.batch)
        pred=out.argmax(dim=1)
        correct +=int((pred==data.y).sum())
    return correct / len(loader.dataset)

for epoch in range(1, 171):
    train()
    train_acc=test(train_loader)
    test_acc=test(test_loader)
    print(f'Epoch:{epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc:{test_acc:.4f}')
    

# %%
